{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de PCA en NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "* Implementación de PCA en NumPy paso a paso\n",
    "* Comparación de resultados con Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dado un dataset $X \\in \\mathbb{R}^{n, d}$, con $n$ muestras y $d$ features, queremos reducir sus dimensiones a $m$. Para ello, el primer paso es centrar el dataset (Hint: usen np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "m = 1\n",
    "\n",
    "# Cada columna es una muestra, cada fila una feature\n",
    "X = np.array([[0.8,0.7],[0.1,-0.1]])\n",
    "\n",
    "# Saco el promedio para cada feature\n",
    "means = np.mean(X,axis=0)\n",
    "X = X - means\n",
    "\n",
    "# stds = np.std(X,axis=0)\n",
    "#X = X / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Obtener la matriz de covarianza de $X^T$, revisar en la teoría por qué utilizamos la transpuesta. Buscar en la documentación de NumPy qué funciones se pueden utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpongo porque me interesa la covarianza entre las features de mis muestras\n",
    "C = np.cov(X.T) / X.shape[0]\n",
    "# C2 = (X*X.T) / 2 #S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calcular los autovalores y autovectores de la matriz de covarianza. Revisar la documentación de NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "aVal, aVec = np.linalg.eig(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Ordernar los autovectores en el sentido de los autovalores decrecientes, revisar la teoría de ser necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.argsort(aVal * -1)\n",
    "val = aVal[indexes]\n",
    "vec = aVec[:,indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Proyectar el dataset centrado sobre los $m$ autovectores más relevantes (Hint: usen np.dot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = vec[:,:m]\n",
    "pX = X.dot(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Consolidar los pasos anteriores en una función o clase PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pca(X,m):\n",
    "    means = np.mean(X,axis=0)\n",
    "    X = X - means\n",
    "    C = np.cov(X.T) / X.shape[0]\n",
    "    aVal, aVec = np.linalg.eig(C)\n",
    "    indexes = np.argsort(aVal * -1)\n",
    "    val = aVal[indexes]\n",
    "    vec = aVec[:,indexes]\n",
    "    B = vec[:,:m] #revisar esto\n",
    "    pX = X.dot(B)\n",
    "    \n",
    "    return pX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Comparar los resultados obtenidos con el modelo de PCA implementado en Scikit-learn ([ver documentación](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)). Tomar como dataset:\n",
    "\n",
    "$X=\\begin{bmatrix}\n",
    "0.8 & 0.7\\\\\n",
    "0.1 & -0.1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Se debe reducir a un componente. Verificar los resultados con np.testing.assert_allclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = np.array([[0.8,0.7],[0.1,-0.1]])\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "rX = pca.fit_transform(X)\n",
    "\n",
    "mX = my_pca(X,1)\n",
    "\n",
    "np.testing.assert_allclose(mX, rX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
